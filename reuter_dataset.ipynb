{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "다중 분류.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP2EewlQn0RsemnOID9mv6+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taegukang35/ML-study/blob/main/reuter_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7lbwHCPCbLK"
      },
      "source": [
        "from keras.datasets import reuters\n",
        "\n",
        "(train_data,train_labels),(test_data,test_labels) = reuters.load_data(num_words=10000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZnfDEryDIWy"
      },
      "source": [
        "len(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rXKKVODDNAt"
      },
      "source": [
        "len(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ett9QafIDOEK"
      },
      "source": [
        "print(train_data[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-wpxLjf_WDE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVgGczsa_WJ1"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKjRnvoVDPC6"
      },
      "source": [
        "word_index = reuters.get_word_index()\n",
        "reverse_word_index = dict([(value,key) for (key,value) in word_index.items()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOP4mlGvDWtY"
      },
      "source": [
        "print(train_data[0])\n",
        "decoded_newswire = ' '.join([reverse_word_index.get(i-3,'?') for i in train_data[0]])\n",
        "print(decoded_newswire)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Tw3RnlPEAWx"
      },
      "source": [
        "def to_one_hot(labels,dimension=46):\n",
        "    results = np.zeros([len(labels),dimension])\n",
        "    for i,label in enumerate(labels):\n",
        "        results[i,label] = 1.\n",
        "    return results\n",
        "\n",
        "one_hot_train_labels = to_one_hot(train_labels)\n",
        "ont_hot_test_labels = to_one_hot(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THphHvSIFfmR"
      },
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "a = to_categorical(train_labels)\n",
        "print(a[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqasSNjNGjyx"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def vectorize_sequences(sequences,dimensions = 10000):\n",
        "    results = np.zeros([len(sequences),dimensions])\n",
        "    for i,sequence in enumerate(sequences):\n",
        "        results[i,sequence] = 1\n",
        "    return results\n",
        "x_train = vectorize_sequences(train_data)\n",
        "x_test = vectorize_sequences(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wc0hC-GxKaDx"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64,activation='relu',input_shape=(10000,)))\n",
        "model.add(layers.Dense(64,activation='relu'))\n",
        "model.add(layers.Dense(46,activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvMJyHoWLAvp"
      },
      "source": [
        "x_val = x_train[:1000]\n",
        "partial_x_train = x_train[1000:]\n",
        "y_val = one_hot_train_labels[:1000]\n",
        "partial_y_train = one_hot_train_labels[1000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY_XtVNlLYcM"
      },
      "source": [
        "history = model.fit(partial_x_train,partial_y_train,epochs=20,batch_size=512,validation_data=(x_val,y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V08cDH31LiYN"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history_dict = history.history\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "epochs = range(1,len(loss)+1)\n",
        "\n",
        "plt.plot(epochs,loss,'bo',label='Training loss')\n",
        "plt.plot(epochs,val_loss,'b',label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BU-nE5eoLtYh"
      },
      "source": [
        "plt.clf()\n",
        "acc = history_dict['accuracy']\n",
        "val_acc = history_dict['val_accuracy']\n",
        "\n",
        "plt.plot(epochs,acc,'bo',label ='Training acc')\n",
        "plt.plot(epochs,val_acc,'b',label='Validation acc')\n",
        "plt.title('Training and Validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Y8MlAMVV2yN"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64,activation='relu',input_shape=(10000,)))\n",
        "model.add(layers.Dense(64,activation='relu'))\n",
        "model.add(layers.Dense(46,activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model.fit(partial_x_train,partial_y_train,epochs=9,batch_size=512,validation_data=(x_val,y_val))\n",
        "results = model.evaluate(x_test,ont_hot_test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gw034VkGZSQZ"
      },
      "source": [
        "print(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uOg1yuQZpCd"
      },
      "source": [
        "prediction = model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rY0tIUQrZ1P3"
      },
      "source": [
        "np.argmax(prediction[0])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}